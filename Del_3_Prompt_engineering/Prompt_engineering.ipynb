{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 0. Initialisering\n",
    "For å komme i gang må vi importere relevante biblioteker og en gyldig openai-nøkkel.\n",
    "For enkelhets skyld definerer vi også en funksjon for å forenkle kall av OpenAI ChatCompletion API'et."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# OpenAI initialisation and additional dependencies\n",
    "import os\n",
    "import openai\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Helper function for calling ChatCompletion API\n",
    "\n",
    "# Alternative models to try: gpt-4-1106-preview, gpt-4, gpt-3.5-turbo-0125, gpt-3.5-turbo, gpt-3.5-turbo-0613\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo-0613\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Grunnleggende prompt engineering-prinsipper, med noen eksempler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.1 Prinsipp 1: Skriv klare og spesifikke instruksjoner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taktikk 1 - Bruk skilletegn for å tydelig indikere distinkte deler av input\n",
    "Ved å bruke skilletegn kan du tydelig indikere distinkte deler av input. Skilletegn kan være: ```, \"\"\", < >, `<tag> </tag>`, `:`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "For a model to work well, just be really clear \\ \n",
    "about what you want. Give specific instructions \\ \n",
    "so the model knows exactly what to do. This helps \\ \n",
    "get the right answers and avoids mistakes. Remember, \\ \n",
    "a short prompt isn't always a clear one. Sometimes, \\ \n",
    "it's better to use longer prompts to give more \\ \n",
    "info to the model. This usually leads to better \\ \n",
    "and more relevant results.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taktikk 2 - Be om en strukturert output\n",
    "Ved å be om en strukturert output kan du få resultater som er enklere å analysere og bruke i applikasjoner. Dette er spesielt nyttig når du vil bruke output i en videre prosess. Eksempler på strukturert output er JSON og HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three fictional banking product names along with their developers and categories. \n",
    "Provide them in JSON format with the following keys: product_id, name, developer, category.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taktikk 3 - Be modellen sjekke om betingelser er oppfylt\n",
    "Modellen kan bli bedt om å gjøre resonnementsteg. For eksempel kan den sjekke en betingelse, og utføre en handling avhengig av resultatet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Example asking the model to check a condition - part 1 - condition met\n",
    "text_1 = f\"\"\"\n",
    "Understanding Insurance Basics is Simple! First, identify the type of coverage you need. \n",
    "While doing that, gather relevant information about your assets and risks. \n",
    "Next, choose a reputable insurance provider and select a suitable policy. \n",
    "Once you've made your decision, go ahead and complete the application process. \n",
    "Wait for the policy to be approved. After approval, review the terms and conditions carefully. \n",
    "If everything looks good, make the required payments to activate your coverage. \n",
    "If needed, consult with an insurance agent for clarification. \n",
    "And there you have it! You've successfully secured insurance coverage for your peace of mind.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt with a conditional instruction + text input\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Example asking the model to check a condition - part 2 - condition not met\n",
    "text_2 = f\"\"\"\n",
    "The stock market is buzzing with activity today, and financial analysts are deep in discussions. \n",
    "It's an intriguing day to explore the dynamics of the financial world. \n",
    "The charts are fluctuating, and economic indicators are being closely monitored. \n",
    "Traders are making strategic moves, and investors are assessing their portfolios. \n",
    "Some are engaged in intense conversations about market trends, while others are researching potential investment opportunities. \n",
    "It's an ideal day to delve into the intricacies of finance and witness the ebb and flow of economic activities.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt with a conditional instruction + text input\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taktikk 4 - Gi eksempler\n",
    "Ved å gi modellen eksempler på ønsket output kan den lære seg å generalisere til lignende tilfeller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Providing a sample conversation\n",
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<client>: Enlighten me about financial planning.\n",
    "\n",
    "<financial_advisor>: The fortune that grows most steadily \\\n",
    "emanates from disciplined savings; the \\\n",
    "most prosperous investment portfolio begins with a single asset; \\\n",
    "the most secure financial future starts with a well-laid plan.\n",
    "\n",
    "<client>: Enlighten me about risk management.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.2 Prinsipp 2: Gi modellen tid til å \"tenke\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"resources/Thinking-Fast-and-Slow.jpg\" alt=\"Prompting principle 2: time to think\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taktikk 1 - Spesifiser trinnene som kreves for å fullføre oppgaven\n",
    "Ved å spesifisere trinnene kan modellen lære å utføre oppgaven trinn for trinn i stedet for å forhaste seg til en konklusjon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Example using complex (and slightly pointless) step by step instructions\n",
    "\n",
    "text = f\"\"\"\n",
    "In a bustling city, siblings Alex and Emma embarked on \\\n",
    "a mission to secure insurance coverage for their \\\n",
    "family. As they navigated the policy options, discussing earnestly, uncertainty \\\n",
    "struck—Alex faced unexpected challenges understanding the terms \\\n",
    "of coverage, and Emma encountered confusing jargon. \\\n",
    "Though slightly perplexed, the duo sought assistance from \\\n",
    "knowledgeable advisors. Despite the confusion, \\\n",
    "their determined efforts prevailed, and they \\\n",
    "left the insurance agency with a sense of security and understanding.\n",
    "\"\"\"\n",
    "\n",
    "# step-by-step instructions:\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple \\\n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following \\\n",
    "keys: french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt_1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taktikk 2 - Instruer modellen til å finne sin egen løsning før den konkluderer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ved å instruere modellen til å utarbeide sin egen løsning før den konkluderer, kan vi unngå dette problemet. I dette eksemplet kan vi se modellen bli \"fristet\" av en enkel løsning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Jumping to wrong conclusion\n",
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm starting a financial consultancy and need assistance\n",
    "working out the budget.\n",
    "- Office space rental costs $50 / square foot \n",
    "- I can purchase computer equipment for $200 / square foot\n",
    "- I negotiated an annual contract for IT support that will cost\n",
    "me a flat $80k per year, and an additional $15 / square\n",
    "foot\n",
    "What is the total budget for the first year of operations\n",
    "as a function of the number of square feet?\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Office cost: 50x\n",
    "2. Solar panel cost: 200x\n",
    "3. Maintenance cost: 80,000 + 150x\n",
    "Total cost: 50x + 200x + 80,000 + 150x = 400x + 80,000\n",
    "\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merk at elevens løsning faktisk ikke er riktig. Vi kan fikse dette ved å instruere modellen til å utarbeide sin egen løsning først."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Thinking things through, and getting it right\n",
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem including the final total. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm starting a financial consultancy and need assistance\n",
    "working out the budget.\n",
    "- Office space rental costs $50 / square foot \n",
    "- I can purchase computer equipment for $200 / square foot\n",
    "- I negotiated an annual contract for IT support that will cost\n",
    "me a flat $80k per year, and an additional $15 / square\n",
    "foot\n",
    "What is the total budget for the first year of operations\n",
    "as a function of the number of square feet?\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Office cost: 50x\n",
    "2. Solar panel cost: 200x\n",
    "3. Maintenance cost: 80,000 + 150x\n",
    "Total cost: 50x + 200x + 80,000 + 150x = 400x + 80,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tre viktige prompt engineering-strategier\n",
    "Eksemplene ovenfor illustrerer hvordan en kan få en LLM-modell til å utføre vanlige oppgaver. Grovt sett kan de klassifiseres innenfor de definerte prompt engineering-strategiene Zero-Shot, Few-Shot og Chain-of-Thoughts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Zero-Shot-prompting\n",
    "\n",
    "LLM-er, som ChatGPT, er utviklet til å følge instruksjoner og er trent på store datamengder. Derfor er de i stand til å utføre noen oppgaver \"zero-shot\". Det betyr at modellen kan utføre en oppgave uten finjustering eller trening. Her er ett av eksemplene vi brukte tidligere som er \"zero-shot\".   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three fictional banking product names along with their developers and categories. \n",
    "Provide them in JSON format with the following keys: product_id, name, developer, category.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merk at ovenfor ga vi ikke modellen noen eksempler på bankprodukter eller JSON-format. Dette er \"zero-shot\"-funksjonen.\n",
    "\n",
    "\n",
    "Når zero-shot ikke fungerer anbefales det å gi demonstrasjoner eller eksempler og det fører oss til \"few-shot\"-prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Few-Shot-prompting\n",
    "\n",
    "Mens LLM'er demonstrerer bemerkelsesverdige \"zero-shot\"-evner kommer de fortsatt til kort ved mer komplekse oppgaver. Few-shot prompting kan brukes for å muliggjøre læring i kontekst, og vi kan dermed gi eksempler for å styre modellen til bedre ytelse. Demonstrasjonene fungerer som kondisjonering for påfølgende eksempler der vi ønsker at modellen skal generere en respons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La oss si at du er en basketballprodusent og ønsker å lage en sentimentanalyse basert på kundeanmeldelser. Da kan du bruke \"Few-Shot\"-prompting for å styre modellen til bedre ytelse. Her er et eksempel på hvordan du kan gjøre det:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Zero-shot attempt\n",
    "prompt = f\"\"\"\n",
    "Determine the sentiment of this sentence.\n",
    "Sentence: This basketball has a lot of weight.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selv om modellen klassifiserer anmeldelsen som nøytral kan en basketball med mye vekt være et defekt produkt. Derfor kan vi bruke \"Few-Shot\"-prompting for å styre modellen til bedre ytelse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Few-shot attempt\n",
    "prompt = f\"\"\"\n",
    "Sentence: This basketball is easy to carry.\n",
    "\n",
    "Answer: The sentiment of this sentence is positive.\n",
    "\n",
    "Determine the sentiment of the sentence.\n",
    "\n",
    "Sentence: This basketball has a lot of weight.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denne gangen klassifiserer modellen anmeldelsen som 'negativ' ettersom den bruker det angitte eksemplet som referanse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selv om \"Few-Shot\"-prompting er en kraftig teknikk har den noen begrensninger - som vist her:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Unsuccessful few-shot attempt at average calculation\n",
    "prompt = f\"\"\"\n",
    "You are an AI assistant capable of performing complex  numerical computations.\n",
    "\n",
    "Question 1:\n",
    "Find the average of the numbers. Here are the numbers: 1, 2, 3.\n",
    "\n",
    "Answer 1:\n",
    "The average is 2.\n",
    "\n",
    "Question 2:\n",
    "Find the average of the numbers. Here are the numbers: 5, 10, 15, 7.\n",
    "\n",
    "Answer 2:\n",
    "The average is 9.25.\n",
    "\n",
    "Question 3:\n",
    "Find the average of the numbers. Here are the numbers: 63409, 95328, 45860, 91378, 210691, 50923, 50760, 99145.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Checking the calculation: \n",
    "x = [63409, 95328, 45860, 91378, 210691, 50923, 50760, 99145]\n",
    "sum(x)/len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som vi kan se er ikke dette svaret riktig og det er behov for mer avansert prompt engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Chain-of-thoughts-prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Chain of thought\"-prompting muliggjør kompleks resonnering gjennom mellomliggende resonnementtrinn. Det kan kombineres med \"Few-Shot\"-prompting for å få bedre resultater på mer komplekse oppgaver som krever resonnering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Average calculation with combined few-shot and chain-of-thoughts prompting\n",
    "prompt = f\"\"\"\n",
    "You are an AI assistant capable of performing complex  numerical computations.\n",
    "\n",
    "Question 1:\n",
    "Find the average of the numbers. Here are the numbers: 1, 2, 3.\n",
    "\n",
    "Answer 1:\n",
    "We start by finding the sum of the numbers. 1+2=3, 3+3=6. The sum of the numbers is 6. Then we divide the sum by the number of numbers. 6/3=2. The average is 2.\n",
    "\n",
    "Question 2:\n",
    "Find the average of the numbers. Here are the numbers: 5, 10, 15, 7.\n",
    "\n",
    "Answer 2:\n",
    "We start by finding the sum of the numbers. 5+10=15, 15+15=30, 30+7=37. The sum of the numbers is 37. Then we divide the sum by the number of numbers. 37/4=9.25. The average is 9.25.\n",
    "\n",
    "Question 3:\n",
    "Find the average of the numbers. Here are the numbers: 63409, 95328, 45860, 91378, 210691, 50923, 50760, 99145.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som vi kan se er modellen i stand til å resonnere rundt spørsmålet og gi et riktig svar når det gis mer detaljerte instruksjoner om hvordan problemet skal løses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prompteksempler for vanlige LLM-oppgaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Er det tydelig forskjell mellom modellene? Hvis ja, hva er forskjellen?\n",
    "2. Hva kan være utfordrende ved bruk av LLM-er og arbeid med prompts?\n",
    "3. Refleksjoner rundt arbeid med prompts fra et utviklerperspektiv.\n",
    "    (Utivkle basert på en eldre/dårligere modell og når jeg har en fungerende flyt, bytter jeg til en nyere/bedre modell.)\n",
    "    (Versjonering av prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Oppsummering\n",
    "### Oppsummering med ord, setninger eller tegngrenser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text for summary examples\n",
    "prod_review = \"\"\"\n",
    "Acquired this 'FjordGuard Assurance' policy for my family's financial security, and they find it reassuring. \n",
    "The coverage is comprehensive, and the policy terms are transparent. The customer service has a welcoming approach, providing a sense of trust. \n",
    "However, I feel the premium is a bit high for the coverage offered. \n",
    "There might be other insurance options with more extensive benefits at a similar cost. \n",
    "Surprisingly, the policy documentation arrived a day earlier than expected, allowing me to review it thoroughly before presenting it to my family.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straightforward summary\n",
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppsummer med et spesifikt fokus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan be om et sammendrag med spesifikt fokus, og få et annet svar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary with specific focus\n",
    " \n",
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review to give feedback to the \\\n",
    "Shipping deparmtment. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words, and focusing on any aspects \\\n",
    "that mention shipping and delivery of the product. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som vi kan se inkluderer oppsummeringene emner som ikke er relatert til fokustemaet. Endring av ordlyden i promptet kan noen ganger gi bedre resultater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asking for information extract instead of a summary\n",
    "prompt = f\"\"\"\n",
    "Your task is to extract relevant information from \\ \n",
    "a product review to give \\\n",
    "feedback to the Shipping department. \n",
    "\n",
    "From the review below, delimited by triple quotes \\\n",
    "extract the information relevant to shipping and \\ \n",
    "delivery. Limit to 30 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Inferering og kategorisering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et standard NLP-problem er sentimentanalyse og vi kan bruke LLM-er til å utføre denne oppgaven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample review text\n",
    "review = \"\"\"\n",
    "Needed a reliable financial advisor for my investments, and NordWealth stood out with additional services and reasonable fees. After purchasing their comprehensive financial planning package, the onboarding process was swift. The communication channel broke during the initial consultation, and the company promptly arranged for a follow-up. The financial plan was delivered within a few days, and the advisor explained it thoroughly. Setting up the investment portfolio was a breeze. I encountered a minor issue, so I contacted their support, and they promptly resolved the matter. NordWealth appears to be an excellent financial service provider that prioritizes its clients and their financial goals!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review sentiment determined using LLM\n",
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "Review text: '''{review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En annen kraftig egenskap av LLM-er er å trekke ut informasjon. Et eksempel der dette er nyttig er når du ønsker å trekke ut informasjon om et produkt eller tjeneste fra anmeldelser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys. \n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "  \n",
    "Review text: '''{review}'''\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM-er er også nyttige til å kategorisere og merke tekst i henhold til innhold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "In a recent governmental survey examining employee satisfaction within the Norwegian financial landscape, participants were tasked with evaluating their contentment levels within their respective banking institutions. The findings illuminated that NorthHarbor Financial Alliance emerged as the leading institution, securing a commendable satisfaction rating of 85%.\n",
    "\n",
    "One employee from NorthHarbor Financial Alliance, Isabella Nordstrøm, shared her perspective on the results, stating, \"The recognition of NorthHarbor doesn't come as a surprise. It's a remarkable workplace with a collaborative culture and ample growth opportunities. I take pride in contributing to such a distinguished financial institution.\"\n",
    "\n",
    "The positive outcomes were warmly embraced by NorthHarbor Financial Alliance's leadership, with CEO Anders Olsen expressing, \"We are elated to witness such robust levels of satisfaction among our dedicated team. Our collective efforts consistently aim for excellence, and it's genuinely fulfilling to see our workforce's contributions acknowledged.\"\n",
    "\n",
    "Conversely, the survey spotlighted that Nordic Finance Collective exhibited the lowest satisfaction rating, with only 38% of employees expressing contentment in their roles. In response, the government has committed to addressing the concerns raised in the survey and is actively working toward enhancing overall job satisfaction throughout the financial sector.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting topics from text\n",
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Transformering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM-er er trent på mange kilder på forskjellige språk - dette gir modellen muligheten til å gjøre oversettelser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effortless translation\n",
    "prompt = f\"\"\"\n",
    "Translate the following English text to Spanish and English pirate: \\ \n",
    "```Hello, I would like to purchase an insurance package.```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tekst kan variere i tone og bør være basert på den tiltenkte målgruppen. LLM-er er svært effektive når det gjelder å endre tonen i en gitt tekst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing tone of voice\n",
    "prompt = f\"\"\"\n",
    "Translate the following from slang to a business letter: \n",
    "'Dude! Joey here. Check out the specs for this savings account.'\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Kundeanmeldelser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under laster vi inn en dataframe med kundeanmeldelsene vi brukte tidligere.\n",
    "\n",
    "Oppgaver:\n",
    "\n",
    "1. Lag en sentimentanalyse og/eller en rangering av anmeldelsene.\n",
    "2. Er det et gjengående tema i de positive/negative anmeldelsene?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_text = pd.read_csv('../Del_2_Litt_om_OpenAI_APIer/data/text_samples_bytt.csv', header=0, sep=';')\n",
    "\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
