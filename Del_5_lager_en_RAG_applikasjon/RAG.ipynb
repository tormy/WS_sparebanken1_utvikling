{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d54fad7-f33e-4ac5-8beb-b7062d69f9cb",
   "metadata": {},
   "source": [
    "# **Viktig**: Kjør cellen nedenfor for å laste inn OpenAI API-nøkkelen for resten av notebooken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f3f21-99b8-4b01-97c1-5a54c6a3b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import Optional\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "doc_address = 'resources/Noria_eBook_The_Insurance_Industry_2025_171205_v8.pdf' #PDF file address for question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ab5f86-7fee-4171-82b8-f8f59d55c217",
   "metadata": {},
   "source": [
    "# Hva er Retrieval Augmented Generation (RAG)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f1923-fdd3-40be-af11-4a81470bdec4",
   "metadata": {},
   "source": [
    "LLM-er har begrenset kunnskap og mangler tilgang til informasjon utenfor treningssettet. Dette begrenser deres evne til å presentere fersk og oppdatert informasjon uten en kontekst om spesifikke emner. I denne delen vil vi utforske måter å tilføre nødvendig kontekst eksternt, slik at LLM-ene kan dra nytte av sin resonnering for å svare på spørsmål basert på korrekte informasjonskilder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f4bcf-49e6-4079-a639-fe8ccad861f1",
   "metadata": {},
   "source": [
    "Retrieval Augmented Generation (RAG) går ut på å øke språkmodellens (LLM) kunnskap ved å integrere ekstra data. Selv om LLM-er kan håndtere en rekke emner er deres forståelse begrenset til offentlig tilgjengelig informasjon opp til et spesifikt treningspunkt. For å muliggjøre resonnering om private data eller data etter treningsperioden er det nødvendig å berike modellens kunnskap med den spesifikke informasjonen som kreves. Denne prosessen, kjent som Retrieval Augmented Generation (RAG), innebærer å hente og inkludere relevant informasjon i modellens prompt.\n",
    "\n",
    "LangChain omfatter ulike komponenter som er spesielt utviklet for å forenkle utviklingen av Q&A-applikasjoner og, mer generelt, RAG-applikasjoner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d0fd1-2f9a-4860-82d0-c817ebc5ede4",
   "metadata": {},
   "source": [
    "## RAG består av to hoveddeler:\n",
    "### 1. Retrieval og generering\n",
    "#### 1. Retrieval: Ved en gitt brukerinput hentes relevante segmenter fra lagring ved hjelp av en Retriever.\n",
    "#### 2. Generer: En ChatModel / LLM produserer en respons ved hjelp av et prompt som inkluderer spørsmålet og den innhentede informasjonen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469c5a7-f6bf-47ce-8610-f569c19bdcbd",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 500px;\">\n",
    "    <img src=\"resources/RAG.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67bec55-c5cd-4d5a-a8b6-b808bc3018ca",
   "metadata": {},
   "source": [
    "Vi skal gå gjennom hvert trinn og konstruere et RAG-system ved ved hjelp av LangChain slik at vi kan chatte med en PDF-fil."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef74de-6fa7-42af-a754-9eceb42f49bd",
   "metadata": {},
   "source": [
    "# 1. Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc3d6c",
   "metadata": {},
   "source": [
    "I dette eksempelet tar vi en nærmere titt på retrieval fra en PDF-fil. Den samme tilnærmingen kan utvides til data i en database, et nettsted, osv.\n",
    "\n",
    "Det første trinnet involverer preprosessering av PDF-filen og består vanligvis av tre steg:\n",
    "\n",
    "1. **Load**: Begynner med å laste inn dataene ved hjelp av ```DocumentLoaders```.\n",
    "2. **Split**: Tekstdelere bryter ned store ```Dokumenter``` i mindre deler. Dette er nyttig både for indeksering av data og for bruk i kombinasjon med en modell, ettersom store deler gir dårligere søkeresultater og ikke passer inn i modellens begrensede kontekstvindu.\n",
    "3. **Store**: Vi trenger et sted å lagre splittet og indeksert data slik at den er tilgjengelig for søk. Dette gjøres oftest ved hjelp av en VectorStore og Embeddings-modell.\n",
    "\n",
    "Vi skal nå gå gjennom hvert steg med tilhørende kode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d7681-29b0-4a30-9332-d772d2d1b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83eec37-96b2-4f8d-920b-6772d1f04d3a",
   "metadata": {},
   "source": [
    "Vi har tilgjengeliggjort en eksempel PDF. Dokumentet består av 25 sider med tekst og på grunn av lengden er det ikke mulig å mate direkte til en LLM. Derfor er det nødvendig å utføre splitting og indeksering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b805fef-bcc4-4761-926f-fa2b7115afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, IFrame\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "pdf_path = doc_address\n",
    "\n",
    "# Create an IFrame to embed the PDF viewer\n",
    "pdf_viewer_iframe = IFrame(src=pdf_path, width=1100, height=900)\n",
    "\n",
    "# Display the IFrame\n",
    "pdf_viewer_iframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767931fc-5998-4fb9-b959-320322575d69",
   "metadata": {},
   "source": [
    "## 1.1 Last inn filen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bb154a-1a9a-49fd-9234-af2f3a56ff99",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 500px;\">\n",
    "    <img src=\"resources/doc_load.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d763aa9b-e3b8-4d32-9051-bc50c8d79037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# Decode the file\n",
    "loader = PyPDFLoader(doc_address)\n",
    "\n",
    "# Check out the text from the PDF\n",
    "loader.load()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e72bd-0cd4-444b-bca5-913fb1aefa0f",
   "metadata": {},
   "source": [
    "## 1.2 Splitt teksten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d9f98-58e3-4648-887c-05b279a992d4",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 500px;\">\n",
    "    <img src=\"resources/doc_split.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf71caa-22b3-4ff7-86db-18df1f48f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "pages = loader.load()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "\n",
    "\n",
    "# Split the document into chunks\n",
    "splits = text_splitter.split_documents(pages)\n",
    "\n",
    "splits[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7318ebf3-eece-4c15-9121-9a335a2fd9de",
   "metadata": {},
   "source": [
    "## 1.3 Embed og lagre teksten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c894c99-438e-4ec9-bc80-1f04803d83ea",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 500px;\">\n",
    "    <img src=\"resources/doc_embed_store.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14b43b4-63af-4d8e-bd09-9550ed32b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# Define the embedding function for the document text\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Create a Chroma vector for searching the documents\n",
    "docsearch = Chroma.from_documents(splits,\n",
    "                                 embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc5b157-590e-4306-8f06-4539da264c89",
   "metadata": {},
   "source": [
    "Et eksempel på en embedded vektor for en av splittene er vist i cellen nedenfor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a3e7f-5d4e-4e6f-bae3-ac1167a69c0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docsearch.get([docsearch.get()['ids'][5]], include=['embeddings', 'documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b1523-ded4-4af5-bc25-341bd8761a0c",
   "metadata": {},
   "source": [
    "Du kan stille forskjellige spørsmål og de splittene med nærmeste kontekst vil bli kalt ved hjelp av ```Chroma``` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6291949-1f95-4548-8745-1f3ae00a1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch.as_retriever().get_relevant_documents('What is Peer-to-Peer (P2P) Insurance?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a8e72e-baa1-48b5-9011-c38f13e1a0b9",
   "metadata": {},
   "source": [
    "# 2. RAG Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62bb52-9fa4-407b-a290-30c9eb5b8621",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 500px;\">\n",
    "    <img src=\"resources/RAG_agent.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f42ef0",
   "metadata": {},
   "source": [
    "Vi skal nå bruke ```LangGraph```, som vi ble kjent med i forrige notebook, for å utvikle en langchain-agent som har tilgang til retrieval-motoren definert som et tool. For å oppnå dette må vi følge to trinn:\n",
    "\n",
    "1. Definer retrieval-tool ved hjelp av innebygde ```langchain```-funksjoner.\n",
    "2. Lag agent-pipline-grafen ved hjelp av ```LangGraph```.\n",
    "\n",
    "Koden for trinnene er i følgende celle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa448b8-baaf-47d6-bab7-c897299a68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Page {page}: {page_content}\")\n",
    "doc_sep = '========='\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    docsearch.as_retriever(),\n",
    "    \"retrieve_insurance_doc\",\n",
    "    \"Use this tool to answer any question about the insurance and finance using the Noria documents\",\n",
    "    document_prompt= prompt,\n",
    "    document_separator=doc_sep\n",
    ")\n",
    "\n",
    "tools = [tool]\n",
    "\n",
    "# We will set streaming=True so that we can stream tokens\n",
    "model = ChatOpenAI(temperature=0, streaming=True)\n",
    "\n",
    "functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "\n",
    "model_with_functions = model.bind_functions(functions)\n",
    "\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def should_retrieve(state):\n",
    "    \"\"\"\n",
    "    Decides whether the agent should retrieve more information or end the process.\n",
    "\n",
    "    This function checks the last message in the state for a function call. If a function call is\n",
    "    present, the process continues to retrieve information. Otherwise, it ends the process.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state of the agent, including all messages.\n",
    "\n",
    "    Returns:\n",
    "        str: A decision to either \"continue\" the retrieval process or \"end\" it.\n",
    "    \"\"\"\n",
    "    print(\"---DECIDE TO RETRIEVE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if \"function_call\" not in last_message.additional_kwargs:\n",
    "        print(\"---DECISION: DO NOT RETRIEVE / DONE---\")\n",
    "        return \"end\"\n",
    "    # Otherwise there is a function call, so we continue\n",
    "    else:\n",
    "        print(\"---DECISION: RETRIEVE---\")\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "### Nodes\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state.\n",
    "\n",
    "    This function calls the agent model to generate a response to the current conversation state.\n",
    "    The response is added to the state's messages.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state of the agent, including all messages.\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the new message added to the list of messages.\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_functions.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define the function to execute tools\n",
    "def call_tool(state):\n",
    "    \"\"\"\n",
    "    Executes a tool based on the last message's function call.\n",
    "\n",
    "    This function is responsible for executing a tool invocation based on the function call\n",
    "    specified in the last message. The result from the tool execution is added to the conversation\n",
    "    state as a new message.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state of the agent, including all messages.\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the new function message added to the list of messages.\n",
    "    \"\"\"\n",
    "    print(\"---EXECUTE RETRIEVAL---\")\n",
    "    messages = state[\"messages\"]\n",
    "    # Based on the continue condition\n",
    "    # we know the last message involves a function call\n",
    "    last_message = messages[-1]\n",
    "    # We construct an ToolInvocation from the function_call\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=json.loads(\n",
    "            last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "        ),\n",
    "    )\n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "    # print(type(response))\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)  # agent\n",
    "workflow.add_node(\"action\", call_tool)  # retrieval\n",
    "\n",
    "\n",
    "# Call agent node to decide to retrieve or not\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    should_retrieve,\n",
    "    {\n",
    "        # Call tool node\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge('action', 'agent')\n",
    "\n",
    "# Compile\n",
    "agent = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf783df-f4f5-48be-8388-62441c11d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"What is the future of insurance?\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "for output in agent.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbcde06-3184-42fe-add5-b3cd082f162b",
   "metadata": {},
   "source": [
    "## Prøv forskjellige spørsmål til dokumentet som er lastet inn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e81b8-3d00-4104-b354-d908aebc7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"...\" ## write the question instead of three dots.\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "for output in agent.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc64e8-079c-4b27-811d-f462dddc9150",
   "metadata": {},
   "source": [
    "# TODO: Chatbot med RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2495a43e-0dd1-48e7-8bfe-0bd9965dcf07",
   "metadata": {},
   "source": [
    "Til slutt ønsker vi å lage et chatbot-grensesnitt for agenten. For å gjøre dette skal vi bruke ***[holoviz Panel library](https://panel.holoviz.org/index.html)*** og lage en klasse for chatbotten. Fyll ut TODO-delene av koden for å fullføre chatbotten og få svar på sprørsmålene til PDF-filen. Chatbot-klassen bruker samme agent som er definert ovenfor. \n",
    "#### !!Det er derfor viktig at alle celler ovenfor er kjørt for at agenten skal fungere\n",
    "\n",
    "Fyll ut feltene angitt med #-kommentarer og fullfør chatbot-klassen og -funksjonene for å se chatboten i aksjon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e775b1c9-a126-48ee-807f-7e4857f28392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import fitz\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "import param\n",
    "import re\n",
    "from langchain_core.messages.function import FunctionMessage\n",
    "from langchain.schema.messages import AIMessage\n",
    "from panel.chat import ChatMessage\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "def chat_handler(contents, user, instance):\n",
    "    # TODO: Try playing around with ChatMessage class to create fancy responses.\n",
    "    # use the instance.generate_response(contents) function to return the answer to the user. \n",
    "\n",
    "    return instance.generate_response(contents)\n",
    "\n",
    "class PDFChatBot(pn.chat.ChatInterface):\n",
    "    \"\"\"\n",
    "    A HoloViz Panel extension providing a front end for a chatbot equipped with RAG tool.\n",
    "\n",
    "    This class extends the `pn.chat.ChatInterface` widget to integrate with a chatbot interface\n",
    "    implemented in Python. It provides a user-friendly chat interface within a Panel\n",
    "    application, allowing users to interact with the underlying chatbot.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    callback: function\n",
    "        The function to handle the response to the user chat message.\n",
    "        \n",
    "    callback_user: str\n",
    "        The name of the chatbot user.\n",
    "\n",
    "    \n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    switch_source_tab:\n",
    "        Switches the active tab to show the source page.\n",
    "    layout:\n",
    "        Returns the Panel layout containing the chat interface and other components.\n",
    "    generate_response:\n",
    "        Generates a response based on the user query and chat history.\n",
    "    render_page:\n",
    "        Renders a specific page of a PDF file as an image.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, *objects, **params):\n",
    "        \"\"\"\n",
    "        Initialize the PDFChatBot.\n",
    "        \"\"\"\n",
    "        self.callback = chat_handler\n",
    "        self.callback_user = 'Assistant'\n",
    "        super(PDFChatBot, self).__init__( *objects, **params)\n",
    "\n",
    "\n",
    "\n",
    "        ##############################################################\n",
    "        ## The page numbers of the returned source material from retrieval engine\n",
    "        ## an array to keep track of chat history\n",
    "        ## the langchain agent defined above\n",
    "        \n",
    "        self.srouce_page_num = [0, 1, 2]\n",
    "        self.chat_history = []\n",
    "        self.agent = agent\n",
    "        ##############################################################\n",
    "\n",
    "        \n",
    "        \n",
    "        self.source_images = [pn.pane.Image(width=500) for _ in range(3)]\n",
    "        \n",
    "\n",
    "        self.source_pane = pn.layout.Row(*self.source_images)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.chage_source_tab_button = pn.widgets.Button(name=\"Show source\", button_type='primary')\n",
    "        # Connect the button click event to the method\n",
    "        self.chage_source_tab_button.on_click(self.switch_source_tab)\n",
    "\n",
    "\n",
    "        self.tabs = pn.Tabs(('Conversation', self), ('Show source page', self.source_pane))\n",
    "        \n",
    "        self.render_page()\n",
    "\n",
    "    ##############################################################\n",
    "    ### Compelete the below function definition.\n",
    "    ## the aim of the function is to answer the input user query using self.agent.\n",
    "    ## if the function call has happened, make the necessary adjustments to update the source pages.\n",
    "    \n",
    "    def generate_response(self, query):\n",
    "        ##TODO: complete this function to generate the response to the user query, \n",
    "        ## Determine whether the openAI function has been called.\n",
    "        \"\"\"\n",
    "        Generate a response based on user query and chat history.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        query : str\n",
    "            User's query.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        answer : str\n",
    "            Returned output from the agent.\n",
    "        function_called : bool\n",
    "            Indicates if a function was called in the response.\n",
    "        \"\"\"\n",
    "        inputs = {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=query\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # TODO: check for function calls and adjust the reponse of the model accordingly.\n",
    "        # The langchain agent is in class property self.agent, you can call it with self.agent.invoke(inputs) \n",
    "        # If the retrieval function is called you need to update the source page numbers from the reponse.\n",
    "        answer = 'default response'\n",
    "        return answer\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def switch_source_tab(self, event):\n",
    "        \"\"\"\n",
    "        Switches the active tab to show the source page.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        event : Event\n",
    "            The event object representing the button click event.\n",
    "        \"\"\"\n",
    "        self.tabs.active = 1 if self.tabs.active == 0 else 1\n",
    "\n",
    "    def layout(self):\n",
    "        \"\"\"\n",
    "        Returns the Panel layout containing the chat interface and other components.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        Panel: The Panel layout containing the chat interface and other components.\n",
    "        \"\"\"\n",
    "        return self.tabs\n",
    "\n",
    "    def render_page(self):\n",
    "        \"\"\"\n",
    "        Renders source pages of a PDF file in the source tab.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None\n",
    "        \"\"\"\n",
    "        doc = fitz.open(doc_address)\n",
    "\n",
    "        \n",
    "        for i, pdf_page in enumerate(self.srouce_page_num[:3]):\n",
    "            page = doc[pdf_page]\n",
    "            pix = page.get_pixmap(matrix=fitz.Matrix(300 / 72, 300 / 72))\n",
    "            image = Image.frombytes('RGB', [pix.width, pix.height], pix.samples)\n",
    "            self.source_images[i].param.update(object=image)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21200d38-8c14-47dd-ac00-481ba955d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = PDFChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bbfc0a-608a-4f93-8a1d-d88ef2c3e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526ca23-4fc4-47fe-b9ee-15c747a1de02",
   "metadata": {},
   "source": [
    "# Du kan prøve dette med andre pdf-filer. Last opp din egen pdf-fil og endre filbanen øverst i denne notebooken."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
