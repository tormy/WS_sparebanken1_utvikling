{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b3ff6d-4b5a-41f9-8fb7-1b946c1b027d",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 300px;\">\n",
    "    <img src=\"resources/langchain.jpeg\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45ee939-6547-4886-b169-5717b227e833",
   "metadata": {},
   "source": [
    "# Effektiv programvareutvikling med hjelp av LLM-er\n",
    "\n",
    "***LangChain*** er et rammeverk designet for å forenkle utviklingen av applikasjoner ved hjelp av store språkmodeller (LLM-er). Det kan brukes til ulike formål som dokumentanalyse og sammendrag, chatbots og kodeanalyse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465a852-2a5c-44a7-9fd2-fbad9e01b2f6",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 600px;\">\n",
    "    <img src=\"resources/langchain_components.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd8cf8-9460-4945-9a6a-9481d6ba05ae",
   "metadata": {},
   "source": [
    "# **Viktig**: Kjør cellen nedenfor for å laste inn OpenAI API-nøkkelen for resten av notebooken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import Optional\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d22b67-201f-4679-8ebc-321d92df175f",
   "metadata": {},
   "source": [
    "# 1. Chains\n",
    "\n",
    "Å bruke en LLM isolert er greit for enkle applikasjoner, men for mer komplekse applikasjoner kreves det å kjede sammen LLM-er. Enten med hverandre eller med andre komponenter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337ebc0-43ac-4e6c-92a0-2850d90da33d",
   "metadata": {},
   "source": [
    "# Hvorfor navnet LangChain?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eff94d-8295-4a3c-a03d-840d26cc63ad",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 80px;\">\n",
    "    <img src=\"resources/simple_chain.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df8313-c9ce-420d-9925-2c8801065f69",
   "metadata": {},
   "source": [
    "Hver operasjon på input eller output til en LLM betraktes som et steg i en chain. Hovedformålet med LangChain er evnen til å \"kjede\" sammen flere steg og lage en kompleks applikasjon som krever flere operasjoner eller kall til forskjellige språkmodeller. \n",
    "\n",
    "LangChain gir et enkelt grensesnitt som gjør det mulig å bygge slike applikasjoner og logikk. En kan også bygge slike applikasjoner uten LangChain, men med store applikasjoner kan kodestørrelse og vedlikehold raskt komme ut av kontroll. Derfor er bruk av LangChain og de medfølgende verktøyene anbefalt for utvikling av LLM-applikasjoner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1be29d-9a39-4d91-a1e6-13313d6e7264",
   "metadata": {},
   "source": [
    "### Lag en enkel chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d133e07e-9482-4dc8-b7a9-b668cc612b26",
   "metadata": {},
   "source": [
    "En enkel chain kan være et steg bestående av å kalle LLM'en med en prompt og be om en spesifikk output. Langchain tilbyr et enkelt og effektivt grensesnitt kalt **L**ang**C**hain **E**xpression **L**anguage (***LCEL***) som forenkler prosessen med å lage chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8f27e-7342-4dc3-96e8-a3b98c169e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Fortell meg om {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.4)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Chain definition is the pipline of putting all the above elements together like below:\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c29c1b-5ceb-4407-8374-a1a0aff23abc",
   "metadata": {},
   "source": [
    "En kan deretter kalle chainen med en inputvariabel ved hjelp av <code>invoke</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf45b22-2ddd-4f1c-b6e0-280f32593973",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke({\"topic\":\"Sverige\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e33b8-7371-4af9-b9c4-fac78ff97ded",
   "metadata": {},
   "source": [
    "**Det kan ta litt tid før output blir generert. Kanskje foretrekker du koden nedenfor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f32b6-8ca2-4b72-b805-c1b307cde8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in chain.stream({\"topic\":\"Bergen\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd27502-7318-4bbe-a97c-cb11dfcd9882",
   "metadata": {},
   "source": [
    "## Langchain tilbyr nyttige verktøy 'out of the box'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a1432f-9b78-43ea-b2fa-61382f66c740",
   "metadata": {},
   "source": [
    "Mange av de tidligere funksjonalitetene vi har sett er allerede tilgjengelige på en enkel måte med LangChain. Du kan dermed utvikle applikasjonene dine raskt og enkelt ved å bruke disse funksjonene. Her er et eksempel på teksttagging og uthenting av nøkkelinformasjon ved hjelp av OpenAI-funksjoner og LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7237b442-aa92-4d10-af22-96a271d9c151",
   "metadata": {},
   "source": [
    "1. Lag først en klasse som inneholder informasjonen du vil trekke ut eller tagger du vil tilordne til teksten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c5ebb2-173f-481e-83de-5da090f4f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Tagging(BaseModel):\n",
    "    \"\"\"Tag the piece of text with particular info.\"\"\"\n",
    "    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\")\n",
    "    language: str = Field(description=\"language of text (should be ISO 639-1 code)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0454b03-108e-42d2-84da-d577531163fe",
   "metadata": {},
   "source": [
    "2. Deretter kan du opprette en tagging chain ved å bruke `.bind()`-metoden i modellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4243cc-d12f-472a-a441-05f80cb638c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "# Define the LLM with temprature \n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Create the prompt for the language model.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Think carefully, and tag the sentence\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Convert the Tagging class to OpenAI function format\n",
    "tagging_functions = [convert_pydantic_to_openai_function(Tagging)] \n",
    "\n",
    "# Add the function to the model using the .bind() method\n",
    "model_with_functions = model.bind(\n",
    "    functions=tagging_functions,\n",
    "    function_call={\"name\": \"Tagging\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627d6ce-debe-4d0b-846d-c0a7de5b0bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the description of the model with binded function.\n",
    "model_with_functions.kwargs['functions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1dd91d-9092-453a-9fb1-22a7d33c483d",
   "metadata": {},
   "source": [
    "3. Lag en chain med modellen ovenfor og den gitte ekstraksjonsprompten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688e54f-01a1-4def-884a-8ad4503a1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118f4a0-c6af-4107-a732-c38685098e6e",
   "metadata": {},
   "source": [
    "4. Test modellen med noen eksempelsetninger på forskjellige språk. (Kan være kreativ her)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c79e1b2-a798-4b42-9a92-f047892a935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain.invoke({\"input\": \"I love langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b0b18-b794-4244-8eb9-3d03ccb67119",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain.invoke({\"input\": \"til helvete med Langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46a44fd-6b5a-4db7-a739-e1a04dbb4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain.invoke({\"input\": \"qué es langchain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b16d01-1d39-47bd-b037-fb4c3b8b608e",
   "metadata": {},
   "source": [
    "Prøv med dine egne setninger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2d597-8f54-4d5b-90dc-70846c558d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain.invoke({\"input\": ...})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae44647-be92-4e28-9474-36826f84d548",
   "metadata": {},
   "source": [
    "## 2. Agenter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1d5af-3436-4276-ac2a-5c79a15dece7",
   "metadata": {},
   "source": [
    "Hovedideen med agenter er å bruke en språkmodell til å velge en sekvens av handlinger. I chains er en sekvens av handlinger hardkodet (i kode). I agenter brukes en språkmodell som en resonnementmotor til å bestemme hvilke handlinger som skal utføres og i hvilken rekkefølge."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8935942c-6328-4ae4-8b18-23791a1eab50",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 260px;\">\n",
    "    <img src=\"resources/llm_agent.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "    <img src=\"resources/langgraph.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4248ba4-0d3f-4cc6-a50e-64d14460b788",
   "metadata": {},
   "source": [
    "## Lag en agent ved hjelp av ***LangGraph***:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10a4d96-2ece-4aff-8f51-755d1aba3606",
   "metadata": {},
   "source": [
    "LangGraph er et bibliotek for å bygge stateful, multi-actor applikasjoner med LLM-er, bygget på toppen av (og ment å brukes med) LangChain. Det utvider ***LangChain Expression Language*** med evnen til å koordinere flere chains over flere trinn av beregning på en syklisk måte. Generell inspirasjon er hentet fra Pregel og Apache Beam, og nåværende grensesnitt er inspirert av ***NetworkX***.\n",
    "\n",
    "\n",
    "**Eksempeloppgaven er å lage en agent som har tilgang til Wikipedia som en utvidet kunnskapskilde. Agenten vil søke på nettsiden hvis den trenger en ekstern kilde for å svare på input.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959046c8-36af-4e42-977c-8e321567ba82",
   "metadata": {},
   "source": [
    "1. Først definerer vi tools/verktøy som vi ønsker å bruke. I dette eksempelet vil vi bruke et søkeverktøy innebygd i Langchain for Wikipedia. Det er imidlertid veldig enkelt å lage dine egne tools/verktøy og de kan tilpasses forskjellige behov og scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c2e969-6df3-49af-af7c-d78f5f809921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun, WikipediaAPIWrapper\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "## Define the input schema for the tool function. In this case the tool accepts a query string as input.\n",
    "\n",
    "class Wikipeida_tool_arg_schema(BaseModel):\n",
    "    \"\"\"Input for the Wikipeida tool.\"\"\"\n",
    "\n",
    "    query: str = Field(description=\"search query to look up\")\n",
    "\n",
    "# A list of tools are provided for the agent to utilize\n",
    "tools = [WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(), args_schema=Wikipeida_tool_arg_schema)]\n",
    "\n",
    "# Wrap these tools in a simple LangGraph ToolExecutor a class that calls that tool, and returns the output\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a7f6e-febc-44f0-ad0b-247f98806a80",
   "metadata": {},
   "source": [
    "\n",
    "Deretter må vi laste inn modellen vi vil bruke. Det er viktig at modellen oppfyller to kriterier:\n",
    "\n",
    "1. Den bør fungere med lister av meldinger. Vi vil representere alle agenttilstander i form av meldinger, så den må fungere godt med dem.\n",
    "\n",
    "2. Den bør fungere med OpenAI-funksjoner. Dette betyr at den enten bør være en OpenAI-modell eller en modell som eksponerer et lignende grensesnitt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170e3271-8971-45e6-929d-43e53dbbd36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.utils.function_calling import format_tool_to_openai_function\n",
    "\n",
    "\n",
    "# We will set streaming=True so that we can stream tokens\n",
    "model = ChatOpenAI(temperature=0, streaming=True)\n",
    "\n",
    "# Converting the LangChain tools into the format for OpenAI function calling, and then bind them to the model class.\n",
    "functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "model_with_functions = model.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0c69c5-d36e-47af-b7b4-6e8449aea8db",
   "metadata": {},
   "source": [
    "## Lage grafer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7623f1-e03d-46aa-9d50-55149d72ebd2",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 552px;\">\n",
    "    <img src=\"resources/langgraph_agent.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8687436-28ea-483a-886f-465af85afab6",
   "metadata": {},
   "source": [
    "### Agenttilstand-definisjon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de949d-8aef-415a-a0b4-c287e1b2ab12",
   "metadata": {},
   "source": [
    "Hovedgrafen i `langgraph` er `StatefulGraph`. Denne grafen er parametrisert av et tilstands-objekt som sendes rundt til hver node. Hver node returnerer deretter operasjoner for å oppdatere tilstanden. Disse operasjonene kan enten SETTE spesifikke attributter for tilstanden (f.eks. overskrive eksisterende verdier) eller LEGGE TIL blant de eksisterende attributtene. Om det skal 'settes' eller 'legges til' angis ved å annotere tilstands-objektet du konstruerer grafen med.\n",
    "\n",
    "For dette eksempelet vil vi spore en liste over meldinger. Vi vil at hver node bare skal legge til meldinger i listen. Derfor vil vi bruke en `TypedDict` med én nøkkel (`messages`) og annotere den slik at det alltid legges til `messages`-attributtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bfa7e-d2e7-4ba5-a552-73cb40f3fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "# Define the state properties that will be passed through the graph\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff511fd-9ca6-4ccd-b537-cd78bd6088f5",
   "metadata": {},
   "source": [
    "## Definer nodefunksjonene til grafen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1608c9fd-0aa8-4b26-a487-3e7a40a07cac",
   "metadata": {},
   "source": [
    "Vi må nå definere forskjellige noder i grafen. I `LangGraph` kan en node enten være en function eller en runnable. Det er to hovednoder vi trenger for dette:\n",
    "\n",
    "1. ***Agenten***: ansvarlig for å bestemme hvilke (om noen) handlinger som skal utføres.\n",
    "2. ***En funksjon***: for å kalle tools/verktøy. Hvis agenten bestemmer seg for å utføre en handling vil denne noden deretter utføre handlingen.\n",
    "\n",
    "\n",
    "La oss definere nodene, samt en funksjon som er definert inne i nodene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d2bbc-259f-46c8-bc57-b6e4ebcfe4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    messages = state['messages']\n",
    "    response = model_with_functions.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define the function to execute tools\n",
    "def call_tool(state):\n",
    "    messages = state['messages']\n",
    "    # Based on the continue condition\n",
    "    # we know the last message involves a function call\n",
    "    last_message = messages[-1]\n",
    "    # We construct an ToolInvocation from the function_call\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"]),\n",
    "    )\n",
    "    print(action)\n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e089a859-a2b3-4852-93ae-a09ffdef54de",
   "metadata": {},
   "source": [
    "## Koble sammen nodene og lag graf-strukturen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2feffa-3a82-4222-883d-a04d70cea618",
   "metadata": {},
   "source": [
    "Vi må også definere noen kanter. Noen kanter kan være betingede ettersom utgangen av en node kan være en av flere alternative stier. Stien som tas er ikke kjent før noden kjøres (LLM'en bestemmer).\n",
    "\n",
    "1. ***Betinget kant***: Etter et agentkall er det to alternativer.   \n",
    "    **a.** Hvis agenten bestemmer en aksjon bør funksjonen for å kalle tools/verktøy kalles.   \n",
    "    **b.** Hvis agenten sier at den er ferdig, så bør den avslutte.   \n",
    "\n",
    "    \n",
    "\n",
    "2. ***Normal kant***: Etter at et tool/verktøy er kalt, bør den alltid gå tilbake til agenten for å bestemme neste steg/handling.\n",
    "\n",
    "\n",
    " \n",
    "La oss koble sammen nodene definert ovenfor med riktige kanter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74240f8-46ba-483e-93aa-003b03830578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tool)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Define the function that determines the route in the conditional edge\n",
    "def should_continue(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if \"function_call\" not in last_message.additional_kwargs:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # We set 'agent' as the starting Node.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings output from the above function, and the values are other nodes' names.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge('action', 'agent')\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a718355e-7b0e-443f-992b-c300b1b458a4",
   "metadata": {},
   "source": [
    "Graf-strukturen er nå komplett og vi kan kalle den ved hjelp av inputmeldinger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9943eb6-4d76-46e2-9e2d-c4e0a231623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Hello how are you?\")]}\n",
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb278a2-6e81-48df-8899-fb11775d49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"What is langchain?\")]}\n",
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb2738e-c4af-4ae4-862d-9ec5010632a8",
   "metadata": {},
   "source": [
    "# TODO: Agent med flere tools/verktøy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a99d82e-947f-44d5-a374-87279eec1ed0",
   "metadata": {},
   "source": [
    "## Prøv å legge til flere tools/verktøy for agenten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9fd69-6057-422c-beea-e5e01e875523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import tool\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    #TODO Define the schema of the input to the tool\n",
    "    a: ... = Field(description=\"...\") # TODO: fill in the blanks with proper object types and description of parameters for the first number\n",
    "    b: ... = Field(description=\"...\") # second number\n",
    "    op: ... = Field(description=\"...\") # operation type\n",
    "\n",
    "@tool(args_schema=CalculatorInput)\n",
    "def calculator_tool(a: ..., b: ..., op: ...) -> int:\n",
    "    \"\"\"...\"\"\" #fill in the description of the tool. This description helps the agent to decide when to use the tool based on the input prompt.\n",
    "    return ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8369bfd4-0411-4933-b411-5fbc76ce0613",
   "metadata": {},
   "source": [
    "## TODO: Legg til nye tools/verktøy definert over til i listen av tools/verktøy for LangGraph-agenten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e29e09-7e2f-4791-a731-b6decf2c1739",
   "metadata": {},
   "source": [
    "The aim is for the agent to have access to both tools of wikipedia search and the custom tool defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba8aeee-870f-4188-9170-a58bb2a12cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of tools are provided for the agent to utilize\n",
    "tools = [...]\n",
    "\n",
    "# Wrap these tools in a simple LangGraph ToolExecutor a class that calls that tool, and returns the output\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "# Bind the language model to the tools defined above.\n",
    "# Use the code above in the agent definition section to get inspiration for this part. The aim is for the tools list to have 2 values :\n",
    "# 1. Wikipeida tool and 2. the custom calculator tool 3. Optional custom tool\n",
    "model = ChatOpenAI(temperature=0, streaming=True)\n",
    "functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "model_with_functions = model.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3cb2c-ca91-4ed1-8dd1-7b868ded884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc4ddb-47e4-4719-993b-96fb2498bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"What is 2375 times 452?\")]}\n",
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
